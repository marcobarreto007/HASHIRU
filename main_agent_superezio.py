# -*- coding: utf-8 -*-
"""
SUPEREZIO - INTERFACE COGNITIVA FINAL
IntegraÃ§Ã£o completa com autonomous_config.py otimizado
Sistema de automaÃ§Ã£o enterprise-level com IA multi-modelo

Desenvolvido por: Marco Barreto, Gemini & ChatGPT
Hardware: RTX 3060 (12GB) + RTX 2060 (6GB)
Otimizado para: Performance + Qualidade balanceados
"""

from __future__ import annotations
import asyncio
import traceback
import chainlit as cl
import sys
import pathlib
import json
import re
import time
import logging
from typing import Dict, List, Any, Optional, Callable, Awaitable
from contextlib import asynccontextmanager

# ----------------------------------------------------------------------
# 1. LOGGING SETUP SUPEREZIO
# ----------------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("superezio.log", encoding="utf-8"), 
        logging.StreamHandler()
    ],
)
logger = logging.getLogger("SUPEREZIO")

# ----------------------------------------------------------------------
# 2. BOOTSTRAPPING SEGURO
# ----------------------------------------------------------------------
ROOT = pathlib.Path(__file__).resolve().parent
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

# ----------------------------------------------------------------------
# 3. IMPORT DA CONFIGURAÃ‡ÃƒO OTIMIZADA
# ----------------------------------------------------------------------
try:
    from autonomous_config import config, get_ai_model, get_fallback_models
    logger.info("âœ… ConfiguraÃ§Ã£o otimizada carregada do autonomous_config.py")
    logger.info(f"ğŸ¯ Hardware: {config.ollama.hardware.gpu_primary} + {config.ollama.hardware.gpu_secondary}")
    logger.info(f"ğŸ’¾ VRAM Total: {config.ollama.hardware.total_vram_gb}GB")
except ImportError:
    logger.warning("âš ï¸ autonomous_config.py nÃ£o encontrado. Usando configuraÃ§Ã£o bÃ¡sica.")
    # Fallback bÃ¡sico
    class BasicConfig:
        def get_model(self, model_type: str) -> str:
            return "llama3.1:8b"
        def get_fallback_models(self, model_type: str) -> List[str]:
            return ["llama3.1:8b", "mistral:7b-instruct"]
    
    config = BasicConfig()
    get_ai_model = config.get_model
    get_fallback_models = config.get_fallback_models

# ----------------------------------------------------------------------
# 4. IMPORTS OPCIONAIS COM TRATAMENTO
# ----------------------------------------------------------------------
httpx = None
try:
    import httpx
    logger.info("âœ… httpx disponÃ­vel para requisiÃ§Ãµes Ollama")
except ImportError:
    logger.warning("âš ï¸ httpx nÃ£o disponÃ­vel - funcionalidades Ollama limitadas")

# ----------------------------------------------------------------------
# 5. COMMAND REGISTRY SUPEREZIO
# ----------------------------------------------------------------------
class CommandInfo:
    def __init__(
        self,
        handler: Callable[..., Any],
        description: str,
        category: str,
        requires_args: bool,
        dangerous: bool,
        auto_allowed: bool,
    ):
        self.handler = handler
        self.description = description
        self.category = category
        self.requires_args = requires_args
        self.dangerous = dangerous
        self.auto_allowed = auto_allowed


class SuperEzioCommandRegistry:
    def __init__(self):
        self.commands: Dict[str, CommandInfo] = {}
        self.categories: Dict[str, List[str]] = {}
        self._load_all()

    def register(
        self,
        command: str,
        handler: Callable[..., Any],
        description: str,
        category: str,
        *,
        requires_args: bool = False,
        dangerous: bool = False,
        auto_allowed: bool = True,
    ) -> None:
        self.commands[command.lstrip("/")] = CommandInfo(
            handler, description, category, requires_args, dangerous, auto_allowed
        )
        self.categories.setdefault(category, []).append(command.lstrip("/"))

    def _load_all(self) -> None:
        """Carrega todos os comandos com error handling individual."""
        for name, loader in (
            ("core", self._load_core_commands),
            ("automation", self._load_automation_commands),
            ("self_modification", self._load_self_commands),
        ):
            try:
                loader()
                logger.info(f"âœ… Comandos '{name}' carregados.")
            except Exception as e:
                logger.info(f"â„¹ï¸ Comandos '{name}' nÃ£o disponÃ­veis: {e}")

    def _load_core_commands(self) -> None:
        """Carrega comandos core bÃ¡sicos do SUPEREZIO."""
        # Comandos bÃ¡sicos sempre disponÃ­veis
        basic_commands = {
            "status": ("ğŸ“Š Status do sistema SUPEREZIO", self._status_handler),
            "models": ("ğŸ¤– Listar modelos disponÃ­veis", self._models_handler),
            "hardware": ("ğŸ’» InformaÃ§Ãµes de hardware", self._hardware_handler),
            "version": ("ğŸ“‹ VersÃ£o do SUPEREZIO", self._version_handler),
        }
        
        for cmd, (desc, handler) in basic_commands.items():
            self.register(cmd, handler, desc, "core", requires_args=False)
        
        logger.info("âœ… Comandos core bÃ¡sicos carregados")

    def _load_automation_commands(self) -> None:
        """Carrega comandos de automaÃ§Ã£o se disponÃ­veis."""
        try:
            import importlib
            automation_module = importlib.import_module("tools.automation_commands")
            handle_automation_command = getattr(automation_module, "handle_automation_command", None)
            
            if not callable(handle_automation_command):
                raise AttributeError("handle_automation_command nÃ£o encontrado")

            automation_cmds = {
                "auto_search": "ğŸ” Buscar na internet",
                "auto_browse": "ğŸŒ Navegar para URL", 
                "auto_click": "ğŸ–±ï¸ Clicar em elemento web",
                "auto_screenshot": "ğŸ“¸ Capturar screenshot",
                "auto_research": "ğŸ”¬ Pesquisa completa automatizada",
                "auto_type": "âŒ¨ï¸ Digitar texto",
                "auto_keys": "ğŸ¹ Pressionar teclas de atalho",
                "auto_folder": "ğŸ“ Abrir pasta",
                "auto_find_files": "ğŸ” Buscar arquivos",
                "auto_status": "ğŸ“Š Status da automaÃ§Ã£o",
            }
            
            for cmd, desc in automation_cmds.items():
                def make_handler(cmd_name):
                    async def handler(args):
                        try:
                            from tools.automation_engine import AutomationEngine
                            engine = AutomationEngine()
                            return await handle_automation_command(cmd_name.replace("auto_", ""), args, engine)
                        except Exception as e:
                            return f"âŒ Erro na automaÃ§Ã£o {cmd_name}: {e}"
                    return handler
                
                self.register(
                    cmd,
                    make_handler(cmd),
                    desc,
                    "automation",
                    requires_args=(cmd != "auto_status"),
                    dangerous=False,
                    auto_allowed=True,
                )
            logger.info("âœ… Comandos de automaÃ§Ã£o carregados")
        except Exception as e:
            logger.info(f"â„¹ï¸ AutomaÃ§Ã£o nÃ£o disponÃ­vel: {e}")

    def _load_self_commands(self) -> None:
        """Carrega comandos de auto-modificaÃ§Ã£o se disponÃ­veis."""
        try:
            import importlib
            selfmod = importlib.import_module("tools.selfmod")
            
            if not hasattr(selfmod, "dispatch"):
                raise AttributeError("selfmod.dispatch nÃ£o encontrado")

            self_cmds = {
                "self:status": "Status do sistema de auto-modificaÃ§Ã£o",
                "self:analyze": "Analisar cÃ³digo atual", 
                "self:plan": "Criar plano de melhorias",
                "self:apply": "Aplicar melhorias automaticamente",
            }
            
            for cmd, desc in self_cmds.items():
                def make_self_handler(cmd_name):
                    async def handler(args):
                        try:
                            return await selfmod.dispatch(f"/{cmd_name}", args)
                        except Exception as e:
                            return f"âŒ Erro em {cmd_name}: {e}"
                    return handler
                
                self.register(
                    cmd,
                    make_self_handler(cmd),
                    desc,
                    "self_modification",
                    requires_args=(cmd != "self:status"),
                    dangerous=(cmd == "self:apply"),
                    auto_allowed=False,
                )
            logger.info("âœ… Comandos de auto-modificaÃ§Ã£o carregados")
        except Exception as e:
            logger.info(f"â„¹ï¸ Auto-modificaÃ§Ã£o nÃ£o disponÃ­vel: {e}")

    # Handlers bÃ¡sicos
    def _status_handler(self, args: str) -> str:
        return f"""## ğŸŒŸ Status do SUPEREZIO

**ğŸ”§ SISTEMA:**
- Comandos carregados: {len(self.commands)}
- Categorias: {len(self.categories)}
- Status: âœ… Operacional

**ğŸ¤– MODELOS ATIVOS:**
- Reasoning: {get_ai_model('reasoning')}
- Code: {get_ai_model('code')}  
- Conversation: {get_ai_model('conversation')}
- Tools: {get_ai_model('tools')}

**ğŸ’¾ HARDWARE:**
- GPU Principal: RTX 3060 (12GB)
- GPU SecundÃ¡ria: RTX 2060 (6GB) 
- VRAM Total: 18GB
"""

    def _models_handler(self, args: str) -> str:
        return f"""## ğŸ¤– Modelos SUPEREZIO

**ğŸ§  REASONING:** `{get_ai_model('reasoning')}`
**ğŸ’» CODE:** `{get_ai_model('code')}`
**ğŸ’¬ CONVERSATION:** `{get_ai_model('conversation')}`
**ğŸ› ï¸ TOOLS:** `{get_ai_model('tools')}`

**ğŸ”„ FALLBACKS DISPONÃVEIS:**
- Reasoning: {', '.join(get_fallback_models('reasoning')[:3])}
- Code: {', '.join(get_fallback_models('code')[:3])}
"""

    def _hardware_handler(self, args: str) -> str:
        try:
            hardware = config.ollama.hardware
            return f"""## ğŸ’» Hardware SUPEREZIO

**ğŸ¯ CONFIGURAÃ‡ÃƒO OTIMIZADA:**
- GPU Principal: {hardware.gpu_primary} ({hardware.vram_primary_gb}GB VRAM)
- GPU SecundÃ¡ria: {hardware.gpu_secondary} ({hardware.vram_secondary_gb}GB VRAM)
- VRAM Total: {hardware.total_vram_gb}GB
- Dual GPU: {'âœ… Ativo' if hardware.is_dual_gpu else 'âŒ Inativo'}

**âš¡ OTIMIZAÃ‡Ã•ES:**
- Memory Management: âœ… Ativo
- Quantization: âœ… Suportado
- Flash Attention: âœ… Habilitado
- Tensor Parallelism: âœ… Dual GPU
"""
        except:
            return "ğŸ’» Hardware: RTX 3060 + RTX 2060 (18GB total)"

    def _version_handler(self, args: str) -> str:
        try:
            version = getattr(config, 'version', '1.0.0')
            build_date = getattr(config, 'build_date', '2025-08-04')
            return f"""## ğŸ“‹ SUPEREZIO Version

**ğŸŒŸ Interface Cognitiva v{version}**
- Build: {build_date}
- Desenvolvido por: Marco Barreto, Gemini & ChatGPT
- Hardware: RTX 3060 + RTX 2060 optimized
- Config: Enterprise-grade with type safety
"""
        except:
            return "ğŸŒŸ SUPEREZIO v1.0 - Interface Cognitiva"

    async def dispatch(self, command: str, args: str = "") -> str:
        """Executa comando com error handling robusto."""
        clean = command.lstrip("/")
        info = self.commands.get(clean)
        if not info:
            return f"âŒ Comando nÃ£o encontrado: {command}. Use `/help`."

        if info.requires_args and not (args or "").strip():
            return f"âŒ Comando '{command}' requer argumentos. {info.description}"

        try:
            result = info.handler(args)
            if asyncio.iscoroutine(result):
                result = await result
            return self._fmt(result)
        except Exception as e:
            logger.error(f"Erro executando '{command}': {e}", exc_info=True)
            return f"âŒ Erro ao executar {command}: {e}"

    @staticmethod
    def _fmt(result: Any) -> str:
        if isinstance(result, dict):
            ok = result.get("success")
            if ok:
                return result.get("message", "âœ… Comando executado com sucesso.")
            return f"âŒ {result.get('error', 'Erro desconhecido.')}"
        return str(result) if result is not None else "âœ… Comando executado."

    def get_help(self, category: Optional[str] = None) -> str:
        help_text = "## ğŸ“š Ajuda do SUPEREZIO\n\n"
        cats = [category] if category and category in self.categories else sorted(self.categories.keys())
        for cat in cats:
            help_text += f"### ğŸš€ Categoria: {cat.upper()}\n"
            for cmd_name in sorted(self.categories.get(cat, [])):
                info = self.commands[cmd_name]
                flag = "âš ï¸ " if info.dangerous else ""
                help_text += f"- **`/{cmd_name}`**: {flag}{info.description}\n"
            help_text += "\n"
        return help_text


# ----------------------------------------------------------------------
# 6. PERFORMANCE MONITOR
# ----------------------------------------------------------------------
class PerformanceMonitor:
    def __init__(self):
        self.metrics: Dict[str, List[float]] = {}

    @asynccontextmanager
    async def measure(self, op: str):
        t0 = time.time()
        try:
            yield
        finally:
            dt = time.time() - t0
            self.metrics.setdefault(op, []).append(dt)
            logger.debug(f"[PERF] {op}: {dt:.3f}s")

    def get_stats_formatted(self) -> str:
        if not self.metrics:
            return "ğŸ“Š Nenhuma mÃ©trica coletada ainda."
        out = "## ğŸ“Š Performance SUPEREZIO\n| OperaÃ§Ã£o | ExecuÃ§Ãµes | MÃ©dio |\n|:--|:--:|:--:|\n"
        for op, ts in self.metrics.items():
            m, n = (sum(ts) / len(ts)), len(ts)
            out += f"| **{op}** | {n} | {m:.3f}s |\n"
        return out


# ----------------------------------------------------------------------
# 7. UTILITIES
# ----------------------------------------------------------------------
def _extract_json_loose(text: str) -> Optional[Dict[str, Any]]:
    """ExtraÃ§Ã£o robusta de JSON de texto."""
    if not text:
        return None
    try:
        cleaned = re.sub(r"```[\s\S]*?```", "", text, flags=re.M)
        start = cleaned.find("{")
        if start != -1:
            depth = 0
            for i in range(start, len(cleaned)):
                c = cleaned[i]
                if c == "{":
                    depth += 1
                elif c == "}":
                    depth -= 1
                    if depth == 0:
                        cand = cleaned[start : i + 1]
                        try:
                            return json.loads(cand)
                        except Exception:
                            break
        return None
    except Exception:
        return None


def _clip(text: str, max_len: int = 5000) -> str:
    """Clipa texto preservando integridade."""
    if text is None:
        return ""
    return text if len(text) <= max_len else text[:max_len] + "\n...(truncado)"


# ----------------------------------------------------------------------
# 8. SUPEREZIO AGENT CORE
# ----------------------------------------------------------------------
class SuperEzioAgent:
    def __init__(self, command_reg: SuperEzioCommandRegistry, perf: PerformanceMonitor):
        self.command_registry = command_reg
        self.perf_monitor = perf
        self.session_id = f"superezio_{int(time.time())}"
        self.http: Optional[Any] = None
        self.automation_available = self._check_automation()
        logger.info("ğŸŒŸ SUPEREZIO Agent inicializado.")

    def _check_automation(self) -> bool:
        """Verifica disponibilidade de automaÃ§Ã£o."""
        try:
            import importlib
            importlib.import_module("tools.automation_commands")
            return True
        except Exception:
            return False

    async def _client(self):
        """Cliente HTTP com fallback seguro."""
        if httpx is None:
            raise RuntimeError("âŒ httpx nÃ£o disponÃ­vel. Instale: pip install httpx")
        
        if self.http is None:
            timeout = getattr(config.ollama, 'timeout', 180.0) if hasattr(config, 'ollama') else 180.0
            self.http = httpx.AsyncClient(timeout=timeout)
        return self.http

    async def call_ollama(self, model_type: str, prompt: str, system: Optional[str] = None) -> str:
        """Chamada Ollama integrada com config otimizado."""
        if httpx is None:
            return "âŒ httpx nÃ£o disponÃ­vel. Funcionalidade Ollama limitada."
            
        try:
            client = await self._client()
            
            # Usa configuraÃ§Ã£o otimizada se disponÃ­vel
            base_url = getattr(config.ollama, 'base_url', 'http://127.0.0.1:11434') if hasattr(config, 'ollama') else 'http://127.0.0.1:11434'
            url = f"{base_url}/api/generate"
            
            # Seleciona modelo otimizado
            model = get_ai_model(model_type)
            payload = {"model": model, "prompt": prompt, "stream": False}
            if system:
                payload["system"] = system

            async with self.perf_monitor.measure("ollama_request"):
                r = await client.post(url, json=payload)
                r.raise_for_status()
                data = r.json()
                response = data.get("response", "") or data.get("message", "")
                logger.debug(f"âœ… Ollama success: {model} ({len(response)} chars)")
                return response
                
        except Exception as e:
            logger.warning(f"âš ï¸ Ollama falhou com {model}: {e}")
            
            # Tenta fallbacks otimizados
            fallbacks = get_fallback_models(model_type)
            for fallback_model in fallbacks[:2]:  # Tenta 2 fallbacks
                try:
                    payload["model"] = fallback_model
                    r = await client.post(url, json=payload)
                    r.raise_for_status()
                    data = r.json()
                    response = data.get("response", "") or data.get("message", "")
                    logger.info(f"âœ… Fallback success: {fallback_model}")
                    return response
                except Exception as fe:
                    logger.debug(f"Fallback {fallback_model} falhou: {fe}")
            
            return f"âŒ NÃ£o foi possÃ­vel contatar Ollama. Erro: {e}"

    async def analyze_intent(self, user_input: str) -> Dict[str, Any]:
        """AnÃ¡lise de intenÃ§Ã£o com IA otimizada."""
        if user_input.startswith("/"):
            return {"tipo": "direct_command", "auto_execute": True}
        
        if httpx is None:
            return {"tipo": "general", "confidence": 0.5}

        try:
            prompt = (
                f'Classifique a intenÃ§Ã£o do usuÃ¡rio e responda APENAS JSON.\n'
                f'Entrada: "{user_input}"\n'
                '{"tipo":"automation|research|code_modification|general","confidence":0.0}'
            )
            raw = await self.call_ollama("reasoning", prompt, "VocÃª Ã© um classificador de intenÃ§Ãµes. Responda sÃ³ JSON.")
            intent = _extract_json_loose(raw) or {"tipo": "general", "confidence": 0.5}
            logger.debug(f"ğŸ§  Intent: {intent}")
            return intent
        except Exception as e:
            logger.warning(f"Falha na anÃ¡lise de intenÃ§Ã£o: {e}")
            return {"tipo": "general", "confidence": 0.3}

    async def execute_plan(self, intent: Dict[str, Any], user_input: str) -> str:
        """ExecuÃ§Ã£o de plano com modelos otimizados."""
        t = intent.get("tipo", "general")
        
        try:
            if t == "direct_command":
                parts = user_input.split(maxsplit=1)
                cmd = parts[0]
                args = parts[1] if len(parts) > 1 else ""
                return await self.command_registry.dispatch(cmd, args)
            elif t in ("automation", "research"):
                if "auto_research" in self.command_registry.commands:
                    return await self.command_registry.dispatch("auto_research", user_input)
                else:
                    return await self.call_ollama("research", f"Pesquise sobre: {user_input}")
            elif t == "code_modification":
                return await self.call_ollama("code", f"Modifique/crie cÃ³digo para: {user_input}")
            else:
                return await self.call_ollama("conversation", user_input)
        except Exception as e:
            logger.error(f"Erro na execuÃ§Ã£o do plano: {e}")
            return f"âŒ Erro na execuÃ§Ã£o: {str(e)}"

    async def cleanup(self) -> None:
        """Cleanup seguro do agente."""
        try:
            if self.http is not None:
                await self.http.aclose()
        except Exception as e:
            logger.warning(f"Erro no cleanup: {e}")
        finally:
            self.http = None
            logger.info("ğŸ§¹ SessÃ£o SUPEREZIO finalizada.")


# ----------------------------------------------------------------------
# 9. INICIALIZAÃ‡ÃƒO GLOBAL
# ----------------------------------------------------------------------
try:
    perf_monitor = PerformanceMonitor()
    command_registry = SuperEzioCommandRegistry()
    agent = SuperEzioAgent(command_registry, perf_monitor)
    
    # Comandos utilitÃ¡rios
    command_registry.register(
        "help", command_registry.get_help, "ğŸ“š Ajuda do SUPEREZIO", "system", requires_args=False
    )
    command_registry.register(
        "perf", perf_monitor.get_stats_formatted, "ğŸ“Š Performance metrics", "system", requires_args=False
    )
    
    logger.info("âœ… SUPEREZIO Agent totalmente inicializado.")
except Exception as e:
    logger.error(f"âŒ Erro crÃ­tico na inicializaÃ§Ã£o: {e}")
    raise

# ----------------------------------------------------------------------
# 10. CHAINLIT HOOKS SUPEREZIO
# ----------------------------------------------------------------------
@cl.on_chat_start
async def on_chat_start():
    """InicializaÃ§Ã£o do chat SUPEREZIO."""
    try:
        # Banner personalizado usando configuraÃ§Ã£o otimizada
        startup_banner = getattr(config, 'startup_banner', 'ğŸŒŸ SUPEREZIO - Interface Cognitiva')
        
        banner = f"""# {startup_banner}

<div class="glass-card">

**ğŸ”§ STATUS OPERACIONAL**
- **Core Engine**: âœ… Funcionando
- **IA Multi-Modelo**: âœ… Ativo  
- **AutomaÃ§Ã£o**: {'âœ… DisponÃ­vel' if agent.automation_available else 'âŒ IndisponÃ­vel'}
- **Interface**: SUPEREZIO v1.0

</div>

**ğŸ¤– MODELOS OTIMIZADOS:**
- **Reasoning**: `{get_ai_model('reasoning')}` (anÃ¡lise avanÃ§ada)
- **Code**: `{get_ai_model('code')}` (programaÃ§Ã£o especializada)  
- **Conversation**: `{get_ai_model('conversation')}` (chat inteligente)
- **Tools**: `{get_ai_model('tools')}` (automaÃ§Ã£o)

**ğŸ’¾ HARDWARE:**
- **GPU Principal**: RTX 3060 (12GB VRAM)
- **GPU SecundÃ¡ria**: RTX 2060 (6GB VRAM)
- **Total VRAM**: 18GB disponÃ­vel

**âš¡ COMANDOS PRINCIPAIS:**
- `/auto_status` - Status da automaÃ§Ã£o
- `/auto_research` - Pesquisa automatizada  
- `/status` - Status do sistema
- `/help` - Lista completa de comandos

<div class="gradient-text">
**SUPEREZIO estÃ¡ pronto para suas tarefas cognitivas! ğŸš€**
</div>
"""
        
        await cl.Message(content=banner, author="SuperEzio").send()
        logger.info(f"ğŸ¬ Chat SUPEREZIO iniciado - sessÃ£o {agent.session_id}")
    except Exception as e:
        logger.error(f"Erro no chat start: {e}")
        await cl.Message(content="ğŸŒŸ SUPEREZIO inicializado (modo bÃ¡sico).").send()


@cl.on_message
async def on_message(message: cl.Message):
    """Handler de mensagem principal do SUPEREZIO."""
    user_input = (message.content or "").strip()
    if not user_input:
        await cl.Message(content="âš ï¸ Mensagem vazia.").send()
        return

    try:
        # Steps com fallback gracioso
        intent = {"tipo": "general", "confidence": 0.5}
        try:
            async with cl.Step(name="ğŸ§  Analisando IntenÃ§Ã£o") as step:
                intent = await agent.analyze_intent(user_input)
                step.output = f"Tipo: **{intent.get('tipo', 'general')}** | ConfianÃ§a: {intent.get('confidence', 0.5):.1f}"
        except Exception as e:
            logger.debug(f"Step anÃ¡lise falhou: {e}")

        result = "âŒ Erro na execuÃ§Ã£o"
        try:
            async with cl.Step(name="ğŸš€ Executando Plano") as step:
                result = await agent.execute_plan(intent, user_input)
                step.output = _clip(result, 1500)
        except Exception as e:
            logger.debug(f"Step execuÃ§Ã£o falhou: {e}")
            result = await agent.execute_plan(intent, user_input)

        # Resposta final com clipping
        final_result = _clip(result, 8000)
        await cl.Message(content=final_result, author="SuperEzio").send()
        logger.info(f"âœ… Mensagem processada: {intent.get('tipo', 'unknown')}")

    except Exception as e:
        error_msg = f"âŒ **Erro do Sistema SUPEREZIO**\n\n```\n{str(e)}\n```\n\nTente novamente ou use `/help`."
        await cl.Message(content=error_msg, author="SuperEzio-Error").send()
        logger.error(f"âŒ Erro crÃ­tico: {e}\n{traceback.format_exc()}")


@cl.on_chat_end
async def on_chat_end():
    """FinalizaÃ§Ã£o do chat SUPEREZIO."""
    try:
        await agent.cleanup()
    except Exception as e:
        logger.warning(f"Erro no cleanup: {e}")


# ----------------------------------------------------------------------
# 11. ENTRY POINT
# ----------------------------------------------------------------------
if __name__ == "__main__":
    try:
        startup_banner = getattr(config, 'startup_banner', 'ğŸŒŸ SUPEREZIO - Interface Cognitiva')
        print(f"\n{startup_banner}")
        print(f"ğŸ“Š Comandos: {len(command_registry.commands)}")
        print(f"ğŸ¤– SessÃ£o: {agent.session_id}")
        print(f"ğŸ’¾ Hardware: RTX 3060 + RTX 2060 ({getattr(config.ollama.hardware, 'total_vram_gb', 18)}GB)")
        print(f"ğŸ§  Modelos: {len(set([get_ai_model(t) for t in ['reasoning', 'code', 'conversation', 'tools']]))}")
        print("\nğŸ§ª Para iniciar: chainlit run main_agent_superezio.py --host 0.0.0.0 --port 8000")
    except Exception as e:
        print(f"ğŸŒŸ SUPEREZIO v1.0 - Interface Cognitiva")
        print(f"ğŸ“Š Sistema bÃ¡sico inicializado")
        print(f"âš ï¸ ConfiguraÃ§Ã£o avanÃ§ada nÃ£o disponÃ­vel: {e}")